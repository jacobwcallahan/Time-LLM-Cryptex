{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5526684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def convert_to_returns(data, keep_high_low=False, keep_volume=True, log_returns=False):\n",
    "    \"\"\"\n",
    "    Convert data to returns.\n",
    "\n",
    "    args:\n",
    "        data: pandas DataFrame with \"close\" and \"volume\" columns\n",
    "        log_returns: bool, if True, the data is converted to log returns\n",
    "        keep_high_low: bool, if True, the high and low prices are kept\n",
    "        keep_volume: bool, if True, the volume column is kept\n",
    "    returns:\n",
    "        pandas DataFrame with \"returns\" and \"volume\" columns\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame({\"close\": data[\"close\"], \"volume\": data[\"volume\"], \"timestamp\": data[\"timestamp\"]})\n",
    "    if log_returns:\n",
    "        data[\"returns\"] = np.log(data[\"close\"] / data[\"close\"].shift(1))\n",
    "    else:\n",
    "        data[\"returns\"] = data[\"close\"] / data[\"close\"].shift(1) - 1\n",
    "    \n",
    "    data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "    final_data = pd.DataFrame()\n",
    "    final_data['returns'] = data['returns']\n",
    "\n",
    "\n",
    "    if keep_high_low:\n",
    "        final_data[\"high\"] = data[\"high\"]\n",
    "        final_data[\"low\"] = data[\"low\"]\n",
    "\n",
    "    if keep_volume:\n",
    "        final_data[\"volume\"] = data[\"volume\"]\n",
    "\n",
    "    final_data[\"timestamp\"] = data[\"timestamp\"]\n",
    "\n",
    "\n",
    "\n",
    "    return final_data\n",
    "\n",
    "def convert_back_to_candlesticks(candlesticks, predicted_returns):\n",
    "    \"\"\"\n",
    "    Convert returns data back to candlesticks. This is used to backtest the model.\n",
    "\n",
    "    args:\n",
    "        data: pandas DataFrame with \"returns\" and \"volume\" columns\n",
    "        \"\"\"\n",
    "    \n",
    "    # Make a copy of the candlesticks data\n",
    "    result = candlesticks.copy()\n",
    "    \n",
    "    # Get the last known close price before predictions start\n",
    "    last_close = result.loc[result.index[predicted_returns['returns_predicted_1'].first_valid_index()-1], 'close']\n",
    "    \n",
    "    # Calculate predicted close prices from returns\n",
    "    for i in range(1, 3):  # For returns_predicted_1 and returns_predicted_2\n",
    "        col = f'returns_predicted_{i}'\n",
    "        if col in predicted_returns.columns:\n",
    "            # Calculate cumulative returns \n",
    "            pred_close = last_close * (1 + predicted_returns[col])\n",
    "            # Rename column\n",
    "            result[f'close_predicted_{i}'] = pred_close\n",
    "\n",
    "    # Convert unix timestamp to UTC datetime\n",
    "    result[\"timestamp\"] = pd.to_datetime(result[\"timestamp\"], unit='s', utc=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "import pandas as pd\n",
    "def agg_data(data, n_times):\n",
    "    \"\"\"\n",
    "    Aggregate OHLCV data by duplicating n times and adjusting values accordingly.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with OHLCV data\n",
    "        n_times: Number of times to duplicate the data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with aggregated data\n",
    "    \"\"\"\n",
    "    # Make a copy of original data\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Calculate price adjustments for each duplicate\n",
    "    # We'll create slight variations around the original prices\n",
    "    variations = np.linspace(-0.001, 0.001, n_times)\n",
    "    \n",
    "    # Initialize list to store duplicated dataframes\n",
    "    dfs = []\n",
    "    \n",
    "    for i in range(n_times):\n",
    "        temp_df = df.copy()\n",
    "        \n",
    "        # Add small variations to prices\n",
    "        adjustment = 1 + variations[i]\n",
    "        temp_df['open'] = temp_df['open'] * adjustment\n",
    "        temp_df['high'] = temp_df['high'] * adjustment\n",
    "        temp_df['low'] = temp_df['low'] * adjustment\n",
    "        temp_df['close'] = temp_df['close'] * adjustment\n",
    "        \n",
    "        # Divide volume by n_times to distribute it\n",
    "        temp_df['volume'] = temp_df['volume'] / n_times\n",
    "        \n",
    "        # If there are predicted columns, apply the same price adjustment\n",
    "        pred_cols = [col for col in temp_df.columns if 'predicted' in col]\n",
    "        for col in pred_cols:\n",
    "            temp_df[col] = temp_df[col] * adjustment\n",
    "            \n",
    "        dfs.append(temp_df)\n",
    "    \n",
    "    # Concatenate all duplicated dataframes\n",
    "    result = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Sort by timestamp to maintain chronological order\n",
    "    result = result.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b92e284d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26205/1144293994.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download('BTC-USD', start='2025-03-01', end='2025-03-28', interval='1h')\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "df = yf.download('BTC-USD', start='2025-03-01', end='2025-03-28', interval='1h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "437443e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to unix time\n",
    "df[\"Date\"] = pd.to_datetime(df.index, utc=True)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).astype(int) / 10**9\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rearranges and renames columns to be the same as the data before\n",
    "df = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "df.columns = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdc5a717",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key, method, tolerance)\u001b[39m\n\u001b[32m   3801\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert to returns and save to csv\u001b[39;00m\n\u001b[32m      3\u001b[39m data_name = \u001b[33m\"\u001b[39m\u001b[33mhourly/ret_h_14d_TEST\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mconvert_to_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_volume\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_high_low\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m df.to_csv(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdataset/cryptex/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mconvert_to_returns\u001b[39m\u001b[34m(data, keep_high_low, keep_volume, log_returns)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_returns\u001b[39m(data, keep_high_low=\u001b[38;5;28;01mFalse\u001b[39;00m, keep_volume=\u001b[38;5;28;01mTrue\u001b[39;00m, log_returns=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    Convert data to returns.\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33;03m        pandas DataFrame with \"returns\" and \"volume\" columns\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     data = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclose\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mvolume\u001b[39m\u001b[33m\"\u001b[39m: data[\u001b[33m\"\u001b[39m\u001b[33mvolume\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: data[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m]})\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m log_returns:\n\u001b[32m     17\u001b[39m         data[\u001b[33m\"\u001b[39m\u001b[33mreturns\u001b[39m\u001b[33m\"\u001b[39m] = np.log(data[\u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m] / data[\u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m].shift(\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/core/frame.py:3806\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   3805\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3806\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3807\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   3808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/core/frame.py:3857\u001b[39m, in \u001b[36mDataFrame._getitem_multilevel\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3855\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   3856\u001b[39m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3857\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3858\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np.ndarray)):\n\u001b[32m   3859\u001b[39m         new_columns = \u001b[38;5;28mself\u001b[39m.columns[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2916\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key, method)\u001b[39m\n\u001b[32m   2913\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   2915\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2916\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   2919\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3263\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3259\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3265\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3266\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3267\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3268\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2849\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2847\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2849\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cryptex/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key, method, tolerance)\u001b[39m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._engine.get_loc(casted_key)\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m-> \u001b[39m\u001b[32m3804\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3805\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3806\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3808\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3809\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'close'"
     ]
    }
   ],
   "source": [
    "# Convert to returns and save to csv\n",
    "\n",
    "data_name = \"hourly/ret_h_14d_TEST\"\n",
    "\n",
    "df = convert_to_returns(df, keep_volume=False, keep_high_low=False)\n",
    "df.to_csv(f\"dataset/cryptex/{data_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97cd6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_back_to_candlesticks(df,pd.read_csv(f\"backtesting/data/ret_h_14d_backtests/inference.csv\"))\n",
    "df.drop(columns=[\"close_predicted_2\"]).to_csv(f\"backtesting/data/ret_h_14d_backtests/inference.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
